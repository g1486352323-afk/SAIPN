import os
import glob
import re
import argparse
import networkx as nx
import importlib
import pandas as pd
import numpy as np
from datetime import datetime
from tqdm import tqdm

# ================= é…ç½®åŒºåŸŸ =================
# é»˜è®¤ä½¿ç”¨ PHEME ç›®å½•ä¸‹ 30min ç²’åº¦çš„æ˜¾å¼/éšå¼è¾“å‡º
EXPLICIT_DIR = '/data_huawei/gaohaizhen/network/saipn/model/PHEME/output/explicit-30min'
IMPLICIT_DIR = '/data_huawei/gaohaizhen/network/saipn/model/PHEME/output/implicit-ablation-30min'
TOP_K_RATIO = 0.10  # ä½¿ç”¨ Top10%
# æ”¯æŒçš„ä¸­å¿ƒæ€§ï¼špagerank / indegree / katz
DEFAULT_METRIC = 'indegree'
# Katz åç«¯ï¼šcpuï¼ˆnx è¿­ä»£ç‰ˆï¼‰æˆ– gpuï¼ˆcugraphï¼‰
DEFAULT_KATZ_BACKEND = 'gpu'
# ===========================================

def parse_timestamp(filename):
    match = re.search(r"(\d{4}-\d{2}-\d{2}_\d{2}-\d{2})", filename)
    if match:
        return datetime.strptime(match.group(1), '%Y-%m-%d_%H-%M')
    match = re.search(r"(\d{4}-\d{2}-\d{2}_\d{4})", filename)
    if match:
        return datetime.strptime(match.group(1), '%Y-%m-%d_%H%M')
    # Metaverse æ˜¾å¼å¿«ç…§ï¼šexplicit-YYYY-MM-DD.edgelistï¼ˆåªæœ‰æ—¥æœŸï¼Œæ²¡æœ‰æ—¶é—´ï¼‰
    match = re.search(r"(\d{4}-\d{2}-\d{2})", filename)
    if match:
        return datetime.strptime(match.group(1), '%Y-%m-%d')
    return None

def collect_files(directory):
    """æ”¶é›†ç›®å½•å†…æ‰€æœ‰å¿«ç…§æ–‡ä»¶å¹¶è§£ææ—¶é—´æˆ³ã€‚"""
    files = sorted(glob.glob(os.path.join(directory, "*.edgelist")))
    if not files:
        files = sorted(glob.glob(os.path.join(directory, 'snapshots', "*.edgelist")))
    files_with_ts = []
    for f in files:
        ts = parse_timestamp(os.path.basename(f))
        if ts:
            files_with_ts.append((ts, f))
    files_with_ts.sort(key=lambda x: x[0])
    return files_with_ts


def compute_scores(G: nx.DiGraph, metric: str, katz_backend: str):
    """æ ¹æ® metric è®¡ç®—èŠ‚ç‚¹å¾—åˆ†."""
    metric = metric.lower()
    if metric == 'indegree':
        # å¸¦æƒå…¥åº¦
        return {n: float(G.in_degree(n, weight='weight')) for n in G.nodes()}
    if metric == 'katz':
        if katz_backend == 'gpu':
            # å°è¯•ä½¿ç”¨ CuGraphï¼ˆç¨€ç– GPU ç‰ˆï¼‰
            try:
                cudf = importlib.import_module("cudf")
                cugraph = importlib.import_module("cugraph")
                if G.number_of_nodes() == 0:
                    return {}
                # ç»„è£…è¾¹è¡¨
                rows = []
                for u, v, d in G.edges(data=True):
                    w = d.get('weight', 1.0)
                    rows.append((u, v, float(w)))
                if not rows:
                    return {}
                pdf = pd.DataFrame(rows, columns=['src', 'dst', 'weight'])
                gdf = cudf.DataFrame.from_pandas(pdf)
                g = cugraph.DiGraph()
                g.from_cudf_edgelist(gdf, source='src', destination='dst', edge_attr='weight', renumber=False)
                res = cugraph.katz_centrality(g, alpha=0.001, beta=1.0, max_iter=200, tol=1e-4)
                # res: cudf with ['vertex','katz_centrality']
                s = res.to_pandas()
                return dict(zip(s['vertex'].astype(str), s['katz_centrality'].astype(float)))
            except Exception as e:
                print(f"[Warn] CuGraph katz failed, fallback to CPU: {e}")
                # å›é€€åˆ° CPU è¿­ä»£ç‰ˆ
        # CPU è¿­ä»£ç‰ˆï¼ˆç¨€ç–ï¼‰
        try:
            return nx.katz_centrality(G, alpha=0.001, beta=1.0, weight='weight', max_iter=200, tol=1e-4)
        except Exception:
            return nx.katz_centrality(G, alpha=0.001, beta=1.0, max_iter=200, tol=1e-4)
    # é»˜è®¤ PageRank
    try:
        return nx.pagerank(G, weight='weight')
    except Exception:
        return nx.pagerank(G)


def dynamic_replay(files_with_ts, metric: str, katz_backend: str, is_explicit=True):
    """
    æŒ‰æ—¶é—´ç´¯ç§¯å›¾ï¼Œè®°å½•é¦–æ¬¡è¿›å…¥ TopK çš„æ—¶é—´ã€‚
    è¿”å›ï¼šburst_times(dict: node->datetime), t0(æœ€æ—©æ—¶é—´)
    """
    if not files_with_ts:
        return {}, None

    G = nx.DiGraph()
    burst_times = {}
    birth_times = {}

    for ts, f in files_with_ts:
        try:
            if is_explicit:
                G_snap = nx.read_edgelist(
                    f, data=(('weight', float), ('type', str)), create_using=nx.DiGraph()
                )
            else:
                G_snap = nx.read_edgelist(
                    f, data=(('weight', float),), create_using=nx.DiGraph()
                )
            G.add_edges_from(G_snap.edges(data=True))

            # è®°å½•é¦–æ¬¡å‡ºç°æ—¶é—´
            for n in G_snap.nodes():
                if n not in birth_times:
                    birth_times[n] = ts
        except Exception as e:
            print(f"[Warn] Fail to load {f}: {e}")
            continue

        if len(G) < 10:
            continue

        scores = compute_scores(G, metric, katz_backend)
        sorted_nodes = sorted(scores.items(), key=lambda x: x[1], reverse=True)
        k = max(1, int(len(sorted_nodes) * TOP_K_RATIO))
        top_nodes = {n for n, _ in sorted_nodes[:k]}

        for node in top_nodes:
            # å»¶è¿Ÿåˆ¤å®šï¼šèŠ‚ç‚¹å‡ºç°å½“æ­¥ä¸è®¡æ ¸å¿ƒï¼Œè‡³å°‘è¿‡1ä¸ªæ—¶é—´æ­¥
            if birth_times.get(node) == ts:
                continue
            if node not in burst_times:
                burst_times[node] = ts

    return burst_times, files_with_ts[0][0]

def parse_args():
    ap = argparse.ArgumentParser()
    ap.add_argument('--explicit-dir', default=EXPLICIT_DIR)
    ap.add_argument('--implicit-dir', default=IMPLICIT_DIR)
    ap.add_argument('--metric', default=DEFAULT_METRIC, choices=['pagerank', 'indegree', 'katz'])
    ap.add_argument('--katz-backend', default=DEFAULT_KATZ_BACKEND, choices=['cpu', 'gpu'])
    return ap.parse_args()


def main():
    args = parse_args()
    explicit_dir = args.explicit_dir
    implicit_dir = args.implicit_dir
    metric = args.metric
    katz_backend = args.katz_backend

    # 1. æ”¶é›†æ–‡ä»¶å¹¶å¯¹é½æ—¶é—´è½´ï¼ˆå–äº¤é›†ï¼‰
    exp_files = collect_files(explicit_dir)
    imp_files = collect_files(implicit_dir)

    if not exp_files or not imp_files:
        print("[Error] æ˜¾å¼æˆ–éšå¼å¿«ç…§ä¸ºç©ºï¼Œæ— æ³•è®¡ç®— CNLRã€‚")
        return

    exp_map = {ts: f for ts, f in exp_files}
    imp_map = {ts: f for ts, f in imp_files}
    common_ts = sorted(set(exp_map.keys()) & set(imp_map.keys()))

    if not common_ts:
        print("[Error] æ˜¾å¼/éšå¼æ—¶é—´æˆ³æ— äº¤é›†ï¼Œæ— æ³•è®¡ç®—ã€‚")
        return

    # æŒ‰äº¤é›†æ—¶é—´è½´é‡æ”¾
    exp_files_aligned = [(ts, exp_map[ts]) for ts in common_ts]
    imp_files_aligned = [(ts, imp_map[ts]) for ts in common_ts]

    print(f"[Info] å¯¹é½åçš„æ—¶é—´ç‚¹æ•°: {len(common_ts)} (å–äº¤é›†)")
    print(f"  æ˜¾å¼é¦–/æœ«æ—¶é—´: {exp_files_aligned[0][0]} -> {exp_files_aligned[-1][0]}")
    print(f"  éšå¼é¦–/æœ«æ—¶é—´: {imp_files_aligned[0][0]} -> {imp_files_aligned[-1][0]}")

    exp_core, exp_t0 = dynamic_replay(exp_files_aligned, metric=metric, katz_backend=katz_backend, is_explicit=True)
    imp_core, imp_t0 = dynamic_replay(imp_files_aligned, metric=metric, katz_backend=katz_backend, is_explicit=False)

    if not exp_core or not imp_core:
        print("[Error] æ— æ³•å¾—åˆ°æ ¸å¿ƒè¿›å…¥æ—¶é—´ï¼Œæ£€æŸ¥ç½‘ç»œæ˜¯å¦è¿‡äºç¨€ç–ã€‚")
        return

    t_start = min(exp_t0, imp_t0)

    print("\n" + "="*60)
    print("ğŸ” DETAILED ANALYSIS REPORT")
    print("="*60)
    
    details = []
    
    for node, t_exp_core in exp_core.items():
        if node not in imp_core:
            continue
        t_imp_core = imp_core[node]

        diff_hours = (t_exp_core - t_imp_core).total_seconds() / 3600.0
        duration_exp_hours = (t_exp_core - t_start).total_seconds() / 3600.0
        if duration_exp_hours <= 0:
            continue

        cnlr_u = diff_hours / duration_exp_hours

        category = "DRAW"
        if diff_hours > 0:
            category = "WIN (Early)"
        elif diff_hours < 0:
            category = "LOSS (Late)"

        details.append({
            'node': node,
            't_start': t_start,
            't_exp_core': t_exp_core,
            't_imp_core': t_imp_core,
            'diff_hours': diff_hours,
            'duration_exp_hours': duration_exp_hours,
            'cnlr': cnlr_u,
            'category': category
        })
            
    df = pd.DataFrame(details)
    
    if df.empty:
        print("No overlap found.")
        return

    out_dir = os.path.dirname(os.path.abspath(__file__))
    detailed_path = os.path.join(out_dir, 'cnlr_detailed.csv')
    df.to_csv(detailed_path, index=False)

    # --- æ‰“å°ç»Ÿè®¡ ---
    print(f"Total Overlap Nodes: {len(df)}")
    print(f"Win: {len(df[df['category'] == 'WIN (Early)'])}")
    print(f"Loss: {len(df[df['category'] == 'LOSS (Late)'])}")
    print(f"Draw: {len(df[df['category'] == 'DRAW'])}")
    
    # --- è¯Šæ–­ 1: æ£€æŸ¥â€œå¹³å±€â€çš„å…·ä½“æ—¶é—´ ---
    print("\n[Diagnosis 1] Inspecting 'DRAW' cases (Sample 5):")
    draws = df[df['category'] == 'DRAW'].head(5)
    if not draws.empty:
        print(draws[['node', 't_exp_core', 't_imp_core', 'diff_hours']].to_string(index=False))
    else:
        print("  No draws.")
        
    # --- è¯Šæ–­ 2: æ£€æŸ¥â€œèµ¢â€çš„å…·ä½“æ—¶é—´ ---
    print("\n[Diagnosis 2] Inspecting 'WIN' cases (Sample 5):")
    wins = df[df['category'] == 'WIN (Early)'].head(5)
    if not wins.empty:
        print(wins[['node', 't_exp_core', 't_imp_core', 'diff_hours']].to_string(index=False))
    else:
        print("  No wins.")

    summary = {
        'total_overlap_nodes': len(df),
        'win_count': int((df['category'] == 'WIN (Early)').sum()),
        'loss_count': int((df['category'] == 'LOSS (Late)').sum()),
        'draw_count': int((df['category'] == 'DRAW').sum()),
        'mean_cnlr': float(df['cnlr'].mean()),
        'median_cnlr': float(df['cnlr'].median()),
        'std_cnlr': float(df['cnlr'].std(ddof=0)),
    }

    summary_df = pd.DataFrame([summary])
    summary_path = os.path.join(out_dir, 'cnlr_summary.csv')
    summary_df.to_csv(summary_path, index=False)

    print("\n" + "="*60)
    print("ğŸ’¡ ç»“è®ºä¸å»ºè®®")
    
    avg_gap = 0
    if len(exp_files) > 1:
         avg_gap = (exp_files[1][0] - exp_files[0][0]).total_seconds()/3600

    if avg_gap >= 6.0:
        print(f"1. ä½ çš„æ—¶é—´ç²’åº¦æ˜¯ {avg_gap} å°æ—¶ã€‚")
        print("   è¿™æ„å‘³ç€å‘ç”Ÿåœ¨ 12:00 åˆ° 18:00 ä¹‹é—´çš„æ‰€æœ‰å˜åŒ–éƒ½è¢«å‹æ‰åœ¨åŒä¸€ä¸ªæ—¶é—´æˆ³ä¸Šäº†ã€‚")
        print("   æ˜¾å¼å’Œéšå¼å¤§æ¦‚ç‡è½åœ¨åŒä¸€ä¸ª6å°æ—¶çª—å£é‡Œï¼Œå¯¼è‡´ Diff=0ã€‚")
        print("   ğŸ‘‰ å»ºè®®ï¼šå¿…é¡»æŠŠæ•°æ®åˆ‡åˆ†å¾—æ›´ç»†ï¼ˆå¦‚ 15åˆ†é’Ÿ æˆ– 1å°æ—¶ï¼‰ã€‚")

if __name__ == '__main__':
    main()