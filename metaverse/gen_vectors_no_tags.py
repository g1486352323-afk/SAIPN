import argparse
from pathlib import Path
import torch
from tqdm import tqdm
import pandas as pd
import re
import os
import numpy as np
from sentence_transformers import SentenceTransformer

# ================= é…ç½® =================
# æ˜¾å¼å®šä¹‰ Base Dirï¼Œé˜²æ­¢ç›¸å¯¹è·¯å¾„åœ¨ä¸åŒæ‰§è¡Œç›®å½•ä¸‹å‡ºé”™
BASE_DIR = Path('/data_huawei/gaohaizhen/network/saipn/model/ablation-d2')

# è¾“å…¥æ–‡ä»¶é»˜è®¤è·¯å¾„ï¼ˆå¯è¢«å‘½ä»¤è¡Œå‚æ•°è¦†ç›–ï¼‰
INPUT_CSV = Path('/data_huawei/gaohaizhen/network/saipn/model/ablation-d2/final_with_sentiment.csv')

# è¾“å‡ºæ–‡ä»¶é»˜è®¤è·¯å¾„ (ä¿å­˜åˆ° embedding ç›®å½•ï¼Œå¯è¢«å‘½ä»¤è¡Œå‚æ•°è¦†ç›–)
OUTPUT_VEC = BASE_DIR / 'embedding' / 'output_vectors_no_tags.txt'
# =======================================

def remove_hashtags(text):
    """ç§»é™¤æ–‡æœ¬ä¸­çš„ #Hashtag"""
    if not isinstance(text, str):
        return ""
    # ç§»é™¤ #å·åŠå…¶åçš„å•è¯ (ä¾‹å¦‚ #JeSuisCharlie -> ç©ºæ ¼)
    # ä¹Ÿå°±æ˜¯åªä¿ç•™çº¯æ–‡æœ¬å†…å®¹ï¼Œæµ‹è¯• Tag å¯¹ç»“æ„çš„å½±å“
    return re.sub(r'#\S+', '', text).strip()

def generate_no_tag_vectors(input_csv: Path = INPUT_CSV, output_vec: Path = OUTPUT_VEC):
    print(f"Input CSV:  {input_csv}")
    print(f"Output Vec: {output_vec}")
    
    if not input_csv.exists():
        print(f"[Error] è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_csv}")
        return

    print(f"æ­£åœ¨è¯»å–æ•°æ®...")
    df = pd.read_csv(input_csv, dtype={'raw_value.id_str': str}, keep_default_na=False)
    
    # è‡ªåŠ¨å¯»æ‰¾åˆ—å
    tcol = next((c for c in ["raw_value.full_text", "full_text", "text", "content", "raw_value.text"] if c in df.columns), None)
    icol = next((c for c in ["raw_value.id_str", "id_str", "id"] if c in df.columns), None)
    
    if not tcol or not icol:
        print(f"[Error] æ‰¾ä¸åˆ°å¿…è¦çš„åˆ—ã€‚å½“å‰åˆ—: {df.columns.tolist()}")
        return

    print(f"æ£€æµ‹åˆ° - æ–‡æœ¬åˆ—: {tcol}, IDåˆ—: {icol}")
    
    # === [æ ¸å¿ƒæ­¥éª¤] æ¸…æ´— Tag ===
    print("æ­£åœ¨æ¸…æ´— Hashtags...")
    ids = df[icol].astype(str).str.strip().tolist()
    raw_texts = df[tcol].fillna("").astype(str).tolist()
    
    # ç§»é™¤ Tag
    clean_texts = []
    for t in tqdm(raw_texts, desc="Cleaning Tags"):
        cleaned = remove_hashtags(t)
        # å¦‚æœæ¸…æ´—åä¸ºç©º (æ¯”å¦‚æ¨æ–‡å…¨æ˜¯Tag)ï¼Œç»™ä¸ªå ä½ç¬¦é˜²æ­¢æŠ¥é”™
        if not cleaned: 
            cleaned = "." 
        clean_texts.append(cleaned)
    
    # åŠ è½½æ¨¡å‹
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"åŠ è½½ SentenceTransformer æ¨¡å‹åˆ° {device}...")
    # ä½¿ç”¨é€šç”¨çš„è½»é‡çº§æ¨¡å‹ï¼Œæˆ–è€…æ¢æˆä½ ä¹‹å‰ç”¨çš„ bert-base-multilingual-cased
    model = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2", device=device)
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_vec.parent.mkdir(parents=True, exist_ok=True)
    
    # æ‰¹é‡ç”Ÿæˆä¸å†™å…¥
    batch_size = 256
    total = len(clean_texts)
    
    print(f"å¼€å§‹ç”Ÿæˆæ—  Tag å‘é‡ (Batch Size: {batch_size})...")
    
    with open(output_vec, "w", encoding="utf-8") as f:
        for i in tqdm(range(0, total, batch_size), desc="Embedding"):
            batch_ids = ids[i : i + batch_size]
            batch_txt = clean_texts[i : i + batch_size]
            
            # ç”Ÿæˆå‘é‡ (numpy array)
            vecs = model.encode(batch_txt, batch_size=batch_size, show_progress_bar=False, convert_to_numpy=True)
            
            # å†™å…¥æ–‡ä»¶
            for tid, v in zip(batch_ids, vecs):
                # æ ¼å¼: id,val1 val2 val3 ...
                vec_str = " ".join([f"{x:.6f}" for x in v])
                f.write(f"{tid},{vec_str}\n")
    
    print(f"âœ… Done! æ—  Tag å‘é‡å·²ä¿å­˜è‡³: {output_vec}")
    print("ğŸ‘‰ ç°åœ¨ä½ å¯ä»¥è¿è¡Œ ablation_no_tags.py äº†")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--input", default=str(INPUT_CSV))
    parser.add_argument("--output", default=str(OUTPUT_VEC))
    args = parser.parse_args()

    generate_no_tag_vectors(input_csv=Path(args.input), output_vec=Path(args.output))